As you’ve just seen, the AI tools make this paper sound very trustworthy and rigorous, but your human reasoning can tell that it’s not.

AI systems _can_ be good at summarising and rephrasing what a paper claims. But they are not designed to notice what’s missing, what’s weakly justified, or what just doesn't make sense.

## What AI is actually doing

AI responds primarily to what is written on the page. It does not independently evaluate whether the methods are appropriate, whether assumptions are justified, or whether the conclusions truly follow.

## What AI misses

<div>
<ul style="margin: 0; padding-left: 18px;">
  <li><strong>Gaps in methods or logic</strong>, missing controls, unclear procedures, or unjustified assumptions.</li>
  <li><strong>Inappropriate analysis</strong>, such as flawed stats.</li>
  <li><strong>Misleading framing</strong>, it often repeats the authors’ narrative, even when that framing is questionable.</li>
  <li><strong>Overconfident conclusions</strong>, unless explicitly prompted, it rarely challenges what the paper claims.</li>
</ul>
</div>

## Use your own brain:

AI is a tool, not a shortcut. Your job as a scholar is to think critically and independently, not to outsource judgement.

## Why this matters

Carrying forward bad science is like making a small mistake in maths. A small error early on gets carried forward. Later steps may look polished and convincing, but the final conclusion is still wrong.

**Bottom line:** trust your critical thinking. It’s more impressive (and far more reliable) than what AI can do!
