<div class="ps-chapter">

<div class="ps-block ps-callout">
  <div class="ps-callout-title">
    <i class="bi bi-lightbulb-fill"></i>
    Main Concept
  </div>
    A small p-value is not inherently meaningful, yet it is often treated as the goal of research. <span class="ps-highlight-term">P-hacking</span> occurs when researchers consciously or unconsciously manipulate analyses, data selection, or reporting to obtain statistically significant results. 
</div>

<div class="ps-divider"></div>

<p class="ps-lede">Some researchers engage in something called p-hacking - <span class="ps-highlight-critical">rarely maliciously, usually unintentionally</span>. This behaviour is often driven by publication incentives, where statistically significant results are more likely to be published, funded, or viewed as “successful” findings</p>

<div class="ps-plain">
  <div class="ps-plain-title">
    <i class="bi bi-translate"></i>
    In plain English
  </div>
  P-hacking is the practice of making analysis decisions in a way that increases the chance of obtaining a statistically significant result, by exploiting flexibility in data analysis.
</div>

## Examples of P-Hacking

<p class="ps-lede">Any of these things might increase the probabilty of a <span class="ps-highlight-term">Type I error (false positive)</span>. In fact, the more analyses you run, the more likely you are to find something statistically significant purely by chance.</p>

<div class="ps-myths">
  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-x-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Checking the results mid-way through collection and stopping once p< 0.05</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-x-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Adding more participants after a “nearly significant” result</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-x-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Testing multiple outcomes but only reporting the significant ones</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-x-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Trying different statistical tests until one gives p < 0.05</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-x-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Excluding certain data points after seeing their impact</div>
    </div>
  </div>
</div>

<div class="ps-divider"></div>

## How to avoid (unintentionally) p-hacking:

<div class="ps-myths">
  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-check-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Pre-registering hypotheses and analysis plans</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-check-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Reporting all measured variables and analyses</div>
    </div>
  </div>

  <div class="ps-myth">
    <div class="ps-myth-icon"><i class="bi bi-check-circle-fill"></i></div>
    <div class="ps-myth-body">
      <div class="ps-myth-title">Being transparent about exclusions and decisions</div>
    </div>
  </div>
</div>

<div class="ps-divider"></div>

<div class="ps-block ps-def">
  <div class="ps-term">The results are the results</div>
  <div>
    Better to report your science with <span class="ps-highlight-critical">integrity</span>, than overinflating the importance of results for a publication.
  </div>
</div>

</div>
